

list = [['db_operations.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/db_operations.py', '\nimport asyncpg\nfrom asyncpg import Connection, Record\n\nfrom typing import Optional\nimport os\nimport json\nfrom datetime import datetime\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# Database connection parameters\nDB_PARAMS = {\n    \'database\': os.environ.get(\'DB_NAME\'),    # should be \'database\' instead of \'dbname\'\n    \'user\': os.environ.get(\'DB_USER\'),\n    \'password\': os.environ.get(\'DB_PASSWORD\'),\n    \'host\': os.environ.get(\'DB_HOST\'),\n    \'port\': os.environ.get(\'DB_PORT\')\n}\n\nasync def  get_db_connection():\n    return await asyncpg.connect(**DB_PARAMS)\n\nasync def create_user_table(email: str):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        # Create table for the user if not exists\n        table_name = f"summaries_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        create_table_query = f"""\n            CREATE TABLE IF NOT EXISTS {table_name}(\n                project_id VARCHAR PRIMARY KEY,\n                status VARCHAR NOT NULL,\n                project_name VARCHAR,\n                project_description VARCHAR,\n                role VARCHAR,\n                summary TEXT,\n                executive_summary TEXT,\n                project_diagrams TEXT,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        """\n        \n        await conn.execute(create_table_query)\n        print(f"Table created for email: {email}")\n\n    except Exception as e:\n        print(f"An error occurred while creating the table: {e}")\n    \n    finally:\n        if conn:\n            await conn.close()\n\nasync def update_status_in_db(emails: str, project_id: str, status: str,  project_name: str, project_description: str, summary: None , executive_summary: None,  project_diagrams: None):\n    \n    try:\n        conn = await get_db_connection()\n        email_list = json.loads(emails)\n\n        for email_info in email_list:\n            email = email_info[\'email\'].replace(\'@\', \'_\').replace(\'.\', \'_\')\n            table_name = f"summaries_{email}"\n\n        \n            # Check if the table exists\n            table_exists = await conn.fetchval("""\n                SELECT EXISTS (\n                    SELECT FROM information_schema.tables \n                    WHERE table_name = $1\n                )\n            """, table_name)\n        \n            \n            if not table_exists:\n                    # If the table doesn\'t exist, create it\n                    await create_user_table(email_info[\'email\'])  \n                \n            # Proceed with the update/insert operation\n            upsert_query = f"""\n                INSERT INTO {table_name} \n                (project_id, status, project_name, project_description, role,  summary, executive_summary, project_diagrams)\n                VALUES ($1,$2,$3,$4,$5,$6,$7,$8)\n                ON CONFLICT (project_id)\n                DO UPDATE SET \n                status = $2, \n                summary = $6, \n                executive_summary = $7, \n                project_diagrams = $8\n            """\n            \n            await conn.execute(upsert_query, project_id, status, project_name, project_description,  email_info[\'role\'], summary, executive_summary, project_diagrams)\n            print(f"Status updated for email: {email_info[\'email\']}, project_id: {project_id}")\n\n    except Exception as e:\n        print(f"An error occurred while updating the status: {e}")\n    \n    finally:\n        if conn:\n            await conn.close()\n\n\nasync def store_summary_in_db(emails: str, project_id: str, summary: str, status: str, executive_summary: str, project_diagrams: str):\n    conn: Optional[Connection] = None\n    try:\n        conn = await get_db_connection()\n        email_list = json.loads(emails)\n\n        for email_info in email_list:\n            email = email_info[\'email\'].replace(\'@\', \'_\').replace(\'.\', \'_\')\n            table_name = f"summaries_{email}"\n            update_query = f"""\n                UPDATE {table_name}\n                SET summary = $2,\n                status = $3,\n                executive_summary = $4,\n                project_diagrams = $5\n                WHERE project_id = $1;\n            """\n            \n            await conn.execute(update_query, project_id, summary, status, executive_summary, project_diagrams)\n\n    except Exception as e:\n        print(f"An error occurred while storing the summary: {e}")\n    \n    finally:\n        if conn:\n            await conn.close()\n\nasync def get_summary_from_db(email: str, project_id: str) -> Optional[str]:\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"summaries_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        select_query = f"""\n            SELECT summary FROM {table_name}\n            WHERE project_id = $1\n            ORDER BY created_at DESC\n            LIMIT 1\n        """\n        \n        result = await conn.fetchrow(select_query, project_id)\n        return result[\'summary\'] if result else None\n\n    except Exception as e:\n        print(f"An error occurred while retrieving the summary: {e}")\n        return None\n    finally:\n        if conn:\n            await conn.close()\n\nasync def get_executive_summary_from_db(email: str, project_id: str) -> Optional[str]:\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"summaries_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        select_query = f"""\n            SELECT  executive_summary FROM {table_name}\n            WHERE project_id = $1\n            ORDER BY created_at DESC\n            LIMIT 1\n        """\n        \n        result = await conn.fetchrow(select_query, project_id)\n        return result[\'executive_summary\'] if result else None\n\n    except Exception as e:\n        print(f"An error occurred while retrieving the executive_summary: {e}")\n        return None\n    \n    finally:\n        if conn:\n            await conn.close()\n\n\n\nasync def get_project_diagrams_from_db(email: str, project_id: str) -> Optional[str]:\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"summaries_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        select_query = f"""\n            SELECT  project_diagrams FROM {table_name}\n            WHERE project_id = $1\n            ORDER BY created_at DESC\n            LIMIT 1\n        """\n        \n        result = await conn.fetchrow(select_query, project_id)\n        return result[\'project_diagrams\'] if result else None\n\n    except Exception as e:\n        print(f"An error occurred while retrieving the project_diagrams: {e}")\n        return None\n    \n    finally:\n        if conn:\n            await conn.close()\n\n\n\n\nasync def create_user_conversation_table(email: str):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"conversations_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        create_table_query = f"""\n            CREATE TABLE IF NOT EXISTS {table_name} (\n                id SERIAL PRIMARY KEY,\n                project_id TEXT NOT NULL,\n                role TEXT NOT NULL,\n                content TEXT NOT NULL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        """\n        \n        await conn.execute(create_table_query)\n\n    except Exception as e:\n        print(f"An error occurred while creating the table: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\nasync def store_conversation_in_db(email: str, project_id: str, role: str, content: str):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        await create_user_conversation_table(email)\n        \n        table_name = f"conversations_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        insert_query = f"""\n            INSERT INTO {table_name} (project_id, role, content)\n            VALUES ($1, $2, $3)\n        """\n        \n        await conn.execute(insert_query, project_id, role, content)\n\n    except Exception as e:\n        print(f"An error occurred while storing the conversation: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\n\nasync def get_conversation_history_from_db(email: str, project_id: str) -> list[dict[str, str]]:\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"conversations_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        \n        # Check if the table exists\n        table_exists = await conn.fetchval("""\n            SELECT EXISTS (\n                SELECT FROM information_schema.tables \n                WHERE table_name = $1\n            )\n        """, table_name)\n        \n        if not table_exists:\n            # If the table doesn\'t exist, create it\n            await create_user_conversation_table(email)\n\n\n        select_query = f"""\n            WITH ranked_messages AS (\n                SELECT role, content, created_at,\n                       ROW_NUMBER() OVER (ORDER BY created_at DESC) as row_num\n                FROM {table_name}\n                WHERE project_id = $1\n            )\n            SELECT role, content\n            FROM ranked_messages\n            WHERE row_num <= 10\n            ORDER BY created_at ASC\n        """\n        \n        results = await conn.fetch(select_query, project_id)\n        return [{"role": row["role"], "content": row["content"]} for row in results]\n\n    except Exception as e:\n        print(f"An error occurred while retrieving the conversation: {e}")\n        return []\n    finally:\n        if conn:\n            await conn.close()\n\nasync def get_user_projects(email: str) -> str:\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"summaries_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        \n        check_table_query = f"""\n            SELECT EXISTS (\n                SELECT  FROM information_schema.tables \n                WHERE table_name = $1\n            )\n        """\n        \n        table_exists = await conn.fetchval(check_table_query, table_name)\n        \n        if not table_exists:\n            return json.dumps({"projects": []})\n\n        select_query = f"""\n            SELECT DISTINCT ON (project_id) project_id, created_at, status, project_name, role, project_description \n            FROM {table_name}\n            ORDER BY project_id, created_at DESC\n        """\n        \n        results = await conn.fetch(select_query)\n        \n        projects = [\n            {\n                "project_name": row["project_name"],\n                "project_id": row["project_id"],\n                "created_at": row["created_at"].isoformat() if isinstance(row["created_at"], datetime) else str(row["created_at"]),\n                "status": row["status"],\n                "project_description": row["project_description"],\n                "role": row["role"]\n            }\n            for row in results\n        ]\n        \n        return json.dumps({"projects": projects})\n\n    except Exception as e:\n        print(f"An error occurred while retrieving user projects: {e}")\n        return json.dumps({"projects": [], "error": str(e)})\n    finally:\n        if conn:\n            await conn.close()\n\n\n\nasync def delete_project_data(email: str, project_id: str):\n    conn = None\n    \n    try:\n        conn = await get_db_connection()\n        details = await get_project_details_by_id(project_id)\n        email_list = json.loads(details[\'emails\'])\n\n        # Extract emails using for loop\n        for item in email_list:\n            email = item[\'email\']\n            role = item[\'role\']\n            # Table names\n            \n            summaries_table_name = f"summaries_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n            conversations_table_name = f"conversations_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n            \n            # Check if summaries table exists\n            summaries_table_exists = await conn.fetchval("""\n                SELECT EXISTS (\n                    SELECT FROM information_schema.tables \n                    WHERE table_name = $1\n                )\n            """, summaries_table_name)\n            \n            if summaries_table_exists:\n                delete_summaries_query = f"""\n                    DELETE FROM {summaries_table_name}\n                    WHERE project_id = $1\n                """\n                await conn.execute(delete_summaries_query, project_id)\n                print(f"Deleted summaries for project_id: {project_id}")\n            else:\n                print(f"Summaries table does not exist for email: {email}")\n            \n            # Check if conversations table exists\n            conversations_table_exists = await conn.fetchval("""\n                SELECT EXISTS (\n                    SELECT FROM information_schema.tables \n                    WHERE table_name = $1\n                )\n            """, conversations_table_name)\n            \n            if conversations_table_exists:\n                delete_conversations_query = f"""\n                    DELETE FROM {conversations_table_name}\n                    WHERE project_id = $1\n                """\n                await conn.execute(delete_conversations_query, project_id)\n                print(f"Deleted conversations for project_id: {project_id}")\n            else:\n                print(f"Conversations table does not exist for email: {email}")\n\n         \n            delete_project_details_query = f"""\n                DELETE FROM {"projects_table"}\n                WHERE project_id = $1\n            """\n            await conn.execute(delete_project_details_query, project_id)\n            print(f"Deleted summaries from project table for project_id: {project_id}")\n          \n        \n    except Exception as e:\n        print(f"An error occurred while deleting project data: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\n\n\nasync def create_user_pin_table(email: str):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"pins_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        create_table_query = f"""\n            CREATE TABLE IF NOT EXISTS {table_name} (\n                id SERIAL PRIMARY KEY,\n                project_id TEXT NOT NULL,\n                topic_name TEXT NOT NULL,\n                pin_content TEXT NOT NULL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        """\n        \n        await conn.execute(create_table_query)\n\n    except Exception as e:\n        print(f"An error occurred while creating the pin table: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\nasync def create_pin_in_db(email: str, project_id: str, topic_name: str, pin_content: str):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        await create_user_pin_table(email)\n        \n        table_name = f"pins_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        insert_query = f"""\n            INSERT INTO {table_name} (project_id, topic_name, pin_content)\n            VALUES ($1, $2, $3)\n        """\n        \n        await conn.execute(insert_query, project_id, topic_name, pin_content)\n\n    except Exception as e:\n        print(f"An error occurred while storing the pin: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\n\nasync def delete_pin_from_db(email: str, pin_id: int):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        # Construct the table name using the user\'s email\n        table_name = f"pins_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        \n        # Prepare the delete query for the specific pin by id\n        delete_query = f"DELETE FROM {table_name} WHERE id = $1"\n        \n        # Execute the delete query\n        result = await conn.execute(delete_query, pin_id)\n        \n        # Check if a record was deleted\n        if result == "DELETE 0":\n            print(f"No pin with id {pin_id} found for user {email}")\n            raise Exception(f"No pin with id {pin_id} found for user {email}")\n\n    except Exception as e:\n        print(f"An error occurred while deleting the pin: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\nasync def get_pins_from_db(email: str, project_id: str):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        # Construct the table name using the user\'s email\n        table_name = f"pins_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        \n        # Prepare the select query to fetch pins based on project_id\n        select_query = f"SELECT * FROM {table_name} WHERE project_id = $1"\n        \n        # Execute the query and fetch results\n        pins = await conn.fetch(select_query, project_id)\n        \n        return pins\n\n    except Exception as e:\n        print(f"An error occurred while fetching the pins: {e}")\n        return None\n    finally:\n        if conn:\n            await conn.close()\n\n\n\nasync def create_project_table():\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        table_name = f"projects_table"\n        create_table_query = f"""\n            CREATE TABLE IF NOT EXISTS {table_name} (\n                id SERIAL PRIMARY KEY,\n                project_id TEXT NOT NULL ,\n                owner_email TEXT NOT NULL,\n                email TEXT NOT NULL,\n                project_name TEXT NOT NULL,\n                project_description TEXT NOT NULL,\n                user_role TEXT NOT NULL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        """\n        \n        await conn.execute(create_table_query)\n\n    except Exception as e:\n        print(f"An error occurred while creating the pin table: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\n\n\nasync def update_project_in_db(project_id :str , owner_email :str, project_name :str, project_description :str, emails :str):\n    conn = None\n    try:\n        conn = await get_db_connection()\n        \n        await create_project_table()\n        \n        table_name = f"projects_table"\n        # Define the insert query\n        insert_query = f"""\n            INSERT INTO {table_name} ( project_id,  owner_email, email, project_name, project_description,  user_role)\n            VALUES ($1, $2, $3, $4, $5, $6)\n        """\n\n        # Insert an entry for the owner\n        await conn.execute(insert_query, project_id, owner_email, owner_email, project_name, project_description, "Owner" )\n\n        # Iterate over the emails dictionary to insert entries for each email\n        for email, role in emails.items():\n            await conn.execute(insert_query, project_id, owner_email, email, project_name, project_description, role)\n\n    except Exception as e:\n        print(f"An error occurred while storing the pin: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\n\nasync def get_project_details_by_id(project_id):\n    \n    try:\n        conn = await get_db_connection()  \n        query = """\n            SELECT \n                owner_email,\n                project_name,\n                project_description,\n                json_agg(json_build_object(\'email\', email, \'role\', user_role)) AS emails\n            FROM \n                projects_table\n            WHERE \n                project_id = $1\n            GROUP BY \n                owner_email, project_name, project_description;\n        """\n        \n        result = await conn.fetchrow(query, project_id)\n        \n        if result:\n            project_details = {\n                "owner_email": result["owner_email"],\n                "project_name": result["project_name"],\n                "project_description": result["project_description"],\n                "emails": result["emails"]\n            }\n            return project_details\n        else:\n            return None\n        \n    except Exception as e:\n        print(f"An error occurred: {e}")\n        return None\n    finally:\n        if conn:\n            await conn.close()    \n\n\nasync def add_user_to_project(project_id, users, owner_email):\n    try:\n        conn = await get_db_connection()\n        email_list = json.loads(users)\n        table_name = f"summaries_{owner_email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        \n        query = f"""\n            SELECT \n                project_name,\n                project_description,\n                status,\n                summary,\n                executive_summary,\n                project_diagrams,\n                created_at        \n            FROM \n                {table_name} \n            WHERE \n                project_id = $1\n           \n        """\n        \n        result = await conn.fetchrow(query, project_id)\n\n        if not result:\n            raise ValueError(f"Project with ID {project_id} not found")\n\n        for email_info in email_list:\n            email = email_info[\'email\'].replace(\'@\', \'_\').replace(\'.\', \'_\')\n            table_name = f"summaries_{email}"\n\n        \n            # Check if the table exists\n            table_exists = await conn.fetchval("""\n                SELECT EXISTS (\n                    SELECT FROM information_schema.tables \n                    WHERE table_name = $1\n                )\n            """, table_name)\n        \n            \n            if not table_exists:\n                    # If the table doesn\'t exist, create it\n                    await create_user_table(email_info[\'email\'])  \n                \n            # Proceed with the update/insert operation\n            insert_query = f"""\n                INSERT INTO {table_name} \n                (project_id, status, project_name, project_description, role,  summary, executive_summary, project_diagrams, created_at)\n                VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9)\n                \n            """\n            \n            await conn.execute(insert_query, project_id, result[\'status\'], result[\'project_name\'], result[\'project_description\'],  email_info[\'role\'], result[\'summary\'], result[\'executive_summary\'], result[\'project_diagrams\'], result[\'created_at\'])\n            print(f"Status updated for email: {email_info[\'email\']}, project_id: {project_id}")\n            project_description = \' \' if not result[\'project_description\'] else result[\'project_description\']\n\n            table_name = f"projects_table"\n            # Define the insert query\n            insert_query = f"""\n                INSERT INTO {table_name} ( project_id, owner_email, email, project_name, project_description,  user_role)\n                VALUES ($1, $2, $3, $4, $5, $6)\n            """\n\n            # Insert an entry for user in the project table \n            await conn.execute(insert_query, project_id, owner_email, email_info[\'email\'], result[\'project_name\'],project_description,  email_info[\'role\'] )\n\n    except Exception as e:\n        print(f"An error occurred while updating the status: {e}")\n    \n    finally:\n        if conn:\n            await conn.close()\n\nasync def delete_user_from_project(email: str, project_id: str):\n    conn = None\n    \n    try:\n        conn = await get_db_connection()\n       \n        summaries_table_name = f"summaries_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        conversations_table_name = f"conversations_{email.replace(\'@\', \'_\').replace(\'.\', \'_\')}"\n        \n        # Check if summaries table exists\n        summaries_table_exists = await conn.fetchval("""\n            SELECT EXISTS (\n                SELECT FROM information_schema.tables \n                WHERE table_name = $1\n            )\n        """, summaries_table_name)\n        \n        if summaries_table_exists:\n            delete_summaries_query = f"""\n                DELETE FROM {summaries_table_name}\n                WHERE project_id = $1\n            """\n            await conn.execute(delete_summaries_query, project_id)\n            print(f"Deleted summaries for project_id: {project_id}")\n        else:\n            print(f"Summaries table does not exist for email: {email}")\n        \n        # Check if conversations table exists\n        conversations_table_exists = await conn.fetchval("""\n            SELECT EXISTS (\n                SELECT FROM information_schema.tables \n                WHERE table_name = $1\n            )\n        """, conversations_table_name)\n        \n        if conversations_table_exists:\n            delete_conversations_query = f"""\n                DELETE FROM {conversations_table_name}\n                WHERE project_id = $1\n            """\n            await conn.execute(delete_conversations_query, project_id)\n            print(f"Deleted conversations for project_id: {project_id}")\n        else:\n            print(f"Conversations table does not exist for email: {email}")\n\n         \n        delete_project_details_query = f"""\n            DELETE FROM {"projects_table"}\n            WHERE project_id = $1 AND email = $2\n        """\n        await conn.execute(delete_project_details_query, project_id, email)\n        print(f"Deleted summaries from project table for project_id: {project_id}")\n          \n        \n    except Exception as e:\n        print(f"An error occurred while deleting project data: {e}")\n    finally:\n        if conn:\n            await conn.close()\n\n\n\n    \n', 'The `db_operations.py` file is a module that manages database operations related to projects, users, summaries, and conversations in an asynchronous environment using `asyncpg`. It establishes connections to a PostgreSQL database to perform create, read, update, and delete (CRUD) operations, creating tables dynamically based on user emails.\n\nThe core features of this file include:\n1. **Database Connection Management**: Implements a function to establish asynchronous connections to a PostgreSQL database using parameters from environment variables.\n2. **CRUD Operations**: Functions to create, retrieve, update, and delete user-specific tables and project data, ensuring that operations are isolated for each user using dynamic table naming based on user emails.\n3. **Users & Projects**: Capabilities for managing user projects including adding/removing users from projects, storing summaries and conversations tied to each project, and handling user pins.\n4. **Dependencies**: The module heavily relies on environment variables for database credentials and requires the `asyncpg` library for database interactions. Additionally, it assumes the existence of a main project table called `projects_table` where project details are stored.\n\nThis file serves as a fundamental component of a larger application that likely aims to manage projects and user interactions within them, supporting collaboration through summaries and conversational history.'], ['app.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/app.py', '#$~ Harmony Engine V3 ~$############################################################################################################################\n#$~ Written by thedataguy ~$#\n"""\nThere are redundant function definitions throughout the api routes, its done to keep all routes independent.\nThe idea is that at one point we can turn the api into microservices architecture without introducing complex interdependencies.\nAlong the same lines, Im trying out a architecture where the code block become self contained since its mostly by AI \n"""\nimport fnmatch\nimport os\nimport zipfile\nimport tempfile\nfrom fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Form, Query, Body\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel \nimport aiofiles  \nimport shutil\nfrom time import sleep\nimport uuid\nimport json\nfrom fastapi.responses import JSONResponse\nimport tiktoken\nfrom typing import List\nimport asyncio\nfrom threading import get_ident\nfrom dotenv import load_dotenv\nimport sys\n#Local Dependencies \nfrom db_operations import store_summary_in_db, get_summary_from_db, update_status_in_db, get_conversation_history_from_db, get_executive_summary_from_db, get_project_diagrams_from_db, create_pin_in_db, delete_pin_from_db, get_pins_from_db, update_project_in_db\nfrom db_operations import get_user_projects as fetch_user_projects, get_project_details_by_id,  add_user_to_project,  delete_user_from_project, get_project_details_by_id\nfrom codebase.summarizer import email_summary, summarize_file, analyze_summary_with_anthropic, update_vectors,  generate_questions_openai, generate_responses, generate_executive_summary, generate_project_diagrams, MAX_CHAR_LIMIT \nimport chat.chat_pro as chat_pro\nimport chat.chat_lite as chat_lite\nimport chat.mermaid  as mermaid\nfrom anthropic import _tokenizers\nfrom delete import delete\nfrom typing import Dict\nfrom typing import Optional\n\n\n\n\n#$~ Configs ~$############################################################################################################################\n\n\nload_dotenv()\n\n"""Needs to be shifted to anthropic based tokenizer"""\ntoken_limit = 170000 # based on open ai\n\n"""Update to support codebases after testing"""\nTEXT_FILE_EXTENSIONS = { \'.dart\', \'.md\', \'.markdown\', \'.js\', \'.ts\', \'.py\', \'.cs\', \'.cpp\', \'.c\', \'.h\', \n                        \'.hpp\', \'.java\', \'.kt\', \'.kts\', \'.rb\', \'.php\', \'.html\', \'.css\', \n                        \'.scss\', \'.less\', \'.xml\', \'.json\', \'.yml\', \'.yaml\', \'.toml\', \n                        \'.ini\', \'.cfg\', \'.txt\', \'.sh\', \'.bat\', \'.ps1\', \'.rs\', \'.go\', \n                        \'.swift\', \'.m\', \'.mm\', \'.pl\', \'.pm\', \'.r\', \'.jl\', \'.scala\', \n                        \'.lua\', \'.sql\', \'.erl\', \'.hrl\', \'.ex\', \'.exs\', \'.dart\', \'.groovy\', \n                        \'.f90\', \'.f95\', \'.f03\', \'.f08\', \'.vb\', \'.vbs\', \'.asm\', \'.s\', \n                        \'.lhs\', \'.hs\', \'.tsx\', \'.jsx\', \'.vue\', \'.ada\', \'.adb\', \'.ads\', \n                        \'.d\', \'.e\', \'.factor\', \'.forth\', \'.ftl\', \'.ml\', \'.mli\', \'.mlp\', \n                        \'.mly\', \'.pp\', \'.pwn\', \'.pug\', \'.razor\', \'.cshtml\', \'.tpl\', \' .agc\'}\n\n\nDEFAULT_IGNORE_PATTERNS = [\n    # Directories\n    \'node_modules\', \'venv\', \'.git\', \'__pycache__\',  \'build\',  \'dist\',\n    # File types\n    \'*.pyc\',  \'*.pyo\',  \'*.so\',   \'*.o\',   \'*.obj\',   \'*.exe\',   \'*.dll\',   \'*.bin\',   \'*.log\',   \'*.tmp\',   \'*.bak\',\n    #Flutter\n    \'.dart_tool\', \'.flutter-plugins\', \'.flutter-plugins-dependencies\', \'.plugin_symlinks\', \'build\', \'*.g.dart\',  \'*.freezed.dart\',  \'*.mocks.dart\', \'*.config.dart\',  \'ios/Pods\', \'android/.gradle\'\n    \n]\n\n\n\n"""Right now its set to allow all, this needs to be restricted\nAuthorization also needs to be implemented"""\napp = FastAPI()\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\'*\'],\n    allow_methods=["*"],  \n    allow_headers=["*"],  \n)\n\n"""All Classes need to be revised, this bit is convoluted"""\nclass AnalyzeSummaryRequest(BaseModel):\n    summary: str\n    user_question: str\n\nclass Project(BaseModel):\n    project_id: str\n    created_at: str\n    status: str\n    project_name :str\n    role: Optional[str] \n    project_description: Optional[str] \n\nclass ProjectsResponse(BaseModel):\n    projects: List[Project]\n\nclass Message(BaseModel):\n    role: str\n    content: str\n\nclass ConversationHistoryResponse(BaseModel):\n    history: List[Message]\n    is_new_chat: bool\n\n#$~ API 1 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis route takes in a zip and emails the files after processing by open ai 4.0 mini model.\nOpen AI is used specificaly to spread the API request load and avoid rate throttling.\nOpen AI is the primary code to Summary LLM.\n"""\n\n#$~ Task List ~$#\n"""\n1) Needs error handling on no files found\n\n\n"""\n\n@app.post("/addcodebase", description="This api takes a codebase or any collection of files as a zip, along with an email. The email will be used to identify the user. Once the intermediate descriptions are generated, a request ID will be provided. This request ID and email id uniquely identify the codebase being processed. A Email notification will be sent to the user")\nasync def add_codebase( file: UploadFile, project_id: str,  background_tasks: BackgroundTasks):\n\n    \n    # Check if the codebase uploaded is actually a zip\n    if not file.filename.endswith(\'.zip\'):\n        raise HTTPException(status_code=400, detail="Invalid file type. Please upload a zip file.")\n    \n    # Temporary directory created in the file system and deleated later\n    temp_dir = tempfile.mkdtemp()\n    project_details = await get_project_details_by_id(project_id)\n    # Create initial entry in database asynchronously\n    await update_status_in_db(emails = project_details["emails"], project_id=project_id, project_description = project_details["project_description"],   project_name = project_details["project_name"],  status="Initiated", summary = None, executive_summary= None, project_diagrams = None)\n    try:\n        zip_path = os.path.join(temp_dir, file.filename)\n\n        # Save the uploaded zip file\n        async with aiofiles.open(zip_path, \'wb\') as f:  \n            contents = await file.read()  \n            await f.write(contents)  \n\n        # Extract the contents of the zip file\n        extract_dir = os.path.join(temp_dir, \'extracted_files\')\n        os.makedirs(extract_dir)\n\n        ### Helper for Zip Extraction\n        def extract_zip_file(zip_path: str, extract_to: str):\n            with zipfile.ZipFile(zip_path, \'r\') as zip_ref:\n             zip_ref.extractall(extract_to)\n\n        loop = asyncio.get_event_loop()  # Acquire the current event loop\n        await loop.run_in_executor(None, extract_zip_file, zip_path, extract_dir) \n\n\n        # Process files in the background\n        background_tasks.add_task(process_and_post_summary, extract_dir, project_details= project_details, project_id= project_id)\n        \n        return {"detail": "File upload successful, generating description in background.",\n                "project_id": project_id,\n                "project_name" :project_details["project_name"]}\n    \n    except Exception as e:\n        shutil.rmtree(temp_dir)\n        await update_status_in_db(emails = project_details["emails"], project_id=project_id, project_description = project_details["project_description"],   project_name = project_details["project_name"] , status = f"Stage 1 Error during file upload: {str(e)}" , summary = None, executive_summary= None, project_diagrams = None)\n        raise HTTPException(status_code=500, detail="Internal server error")\n    \n\n# Iterate through each file in zip and call Open AI to generate the summary \n\n#`````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````\ndef should_ignore_path(path, ignore_patterns=DEFAULT_IGNORE_PATTERNS):\n    path_parts = path.split(os.sep)\n    for pattern in ignore_patterns:\n        if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\n            return True\n    return False\n\nasync def process_and_post_summary(extract_dir: str, project_id: str, project_details: str ):\n    try:\n        # Status update in db\n        await update_status_in_db(emails = project_details["emails"], project_id=project_id, project_description = project_details["project_description"],   project_name = project_details["project_name"],  status = "Summary being generated" , summary ="", executive_summary= "", project_diagrams= "")\n        summaries: list[str] = []\n\n        async def gather_files():\n            context_summaries = []\n            full_summaries = []\n\n            for root, dirs, files in os.walk(extract_dir):\n                dirs[:] = [d for d in dirs if not should_ignore_path(os.path.join(root, d), DEFAULT_IGNORE_PATTERNS)]\n\n                for name in files:\n                    file_path = os.path.join(root, name)\n                    relative_path = os.path.relpath(file_path, extract_dir)\n                    \n                    # Check if the file should be ignored\n                    if should_ignore_path(relative_path):\n                        continue\n                    \n                    if os.path.splitext(name)[1].lower() in TEXT_FILE_EXTENSIONS:               \n                        file_path_1, content, summary  = await summarize_file(file_path )\n                        print(f\'Summary succeded for {file_path}\')\n                        if summary:\n                            file_name = os.path.basename(file_path)\n                            context_summary = f"file name is {file_name}, \\nfile path is: {file_path_1}, \\nfilesummary is: {summary}"\n                            full_summary = [file_name, file_path,content,summary]\n                            context_summaries.append(context_summary)\n                            full_summaries.append(full_summary)             \n            return context_summaries, full_summaries \n        \n\n        context_summaries, full_summaries = await gather_files()\n        ###\n        if context_summaries:\n            combined_summary = \'\\n\\n\\n\'.join([item for sublist in context_summaries for item in (sublist if isinstance(sublist, list) else [sublist])])\n\n              # Truncate the combined summary to 160,000 tokens\n            tokenizer = _tokenizers.sync_get_tokenizer()\n\n            # Tokenize the summary\n            tokens = tokenizer.encode(combined_summary).ids\n\n            # Set the maximum number of tokens \n            max_tokens = 160000 # lower this post test\n\n            # Truncate if necessary\n            if len(tokens) > max_tokens:\n                truncated_tokens = tokens[:max_tokens]\n                combined_summary = tokenizer.decode(truncated_tokens)\n\n\n            await update_vectors(project_id= project_id, full_summaries = full_summaries)\n\n            executive_summary = await generate_executive_summary(combined_summary)\n\n            diagrams = await generate_project_diagrams(project_id =project_id,summary= combined_summary )\n\n            await store_summary_in_db(emails= project_details["emails"], project_id= project_id, summary= combined_summary, status="Stage 1 Completed", executive_summary = executive_summary, project_diagrams = diagrams)\n           \n            email_summary(combined_summary, project_details["emails"], project_id, project_details["project_name"])\n            print("email sent")\n        else:\n            await update_status_in_db(emails = project_details["emails"], project_id=project_id, project_description = project_details["project_description"],   project_name = project_details["project_name"], status=  "Stage 1 No summaries generated, Contact: sai_002@harmonyengine.ai ", summary = None, executive_summary= None, project_diagrams = None)\n            print("no files were found")\n            pass\n    except Exception as e:\n        error_msg = f"Error in process_and_post_summary: {str(e)}"\n        print(error_msg)\n        await update_status_in_db(emails = project_details["emails"], project_id=project_id, project_description = project_details["project_description"],   project_name = project_details["project_name"], status = error_msg,  summary = None, executive_summary = None,  project_diagrams = None)\n    \n    \n    finally:\n            shutil.rmtree(extract_dir)\n\n#$~ API 2 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis route fetches the summary based on request id and email.\nbased on that generates questions, then chats with the codebase summary to pull outmore details\nAnthropic for chat, Open AI to convert the response to JSON.\nDepricated\n"""\n\n#$~ Task List ~$#\n"""\n- Depriicated \n\n"""\n\n@app.post("/generate-summary", description="   WARNINING DEPRICATED: Generates a comprehensive report of the codebase.")\n\nasync def analyze_summary(background_tasks: BackgroundTasks, email: str = Form(...), project_id: str = Form(...)):\n   \n    try:\n        # Fetch summary from PostgreSQL\n        summary_content = await get_summary_from_db(email, project_id)\n        if not summary_content:\n            #update_status_in_db(email, project_id, "Stage 2 Error: Summary not found")\n            raise HTTPException(status_code=404, detail="Summary not found")\n\n        enc = tiktoken.encoding_for_model("gpt-4")  # Modify as needed for Anthropic\n        tokens = enc.encode(summary_content)\n        token_count = len(tokens)\n        if token_count > token_limit:\n            truncated_tokens = tokens[:token_limit]\n            summary_content = enc.decode(truncated_tokens)\n\n        #update_status_in_db(email, project_id, "STAGE 2 Summary retrieved successfully")\n\n    except Exception as e:\n        #update_status_in_db(email, project_id, f"Error: STAGE 2 Failed to retrieve summary - {str(e)}")\n        raise HTTPException(status_code=400, detail=f"Failed to retrieve summary: {str(e)}")\n\n    background_tasks.add_task(process_summary, email, summary_content, project_id)\n    \n    return JSONResponse(content={"detail": "Summary retrieved successfully, processing in background. You will receive an email shortly"})\n\nasync def process_summary(email: str, summary_content: str, project_id: str):\n\n    # use the summary to set up a base set of questions from anthropic, this is then fed to open ai to get structured questions. \n    #either use anthropic fully - needs the response to be in json or use open ai fully - right now this is hack code\n    question, executive_summary = analyze_summary_with_anthropic(summary_content)   ##############verify if this step is needed\n   \n    try:\n       \n        #update_status_in_db(email, project_id, "STAGE 2 Processing with OpenAI assistant")\n\n        final_question =  await generate_questions_openai(question)\n        print("generated : questions /n " )\n        await generate_responses(final_question , email, summary_content, project_id, executive_summary )\n    \n    except Exception as e:\n        #update_status_in_db(email, project_id, f"STAGE 2 Error in process_summary: {str(e)}")\n        print(f"Error in process_summary: {e}")\n\n\n\n#$~ API 3 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis route fetches the summary from DB and uses Anthropic Prompt caching to let users chat with the codebase.\nThis is currently depricated >> Retaining the code so that I can turn this route into a Lite-chat for free users.\nAnthropic for chat.\nMessage History - Last 5 turns of the conversation.\nDepricated\n"""\n\n#$~ Task List ~$#\n"""\n1) Model encoding - change it to anthropic tokenizer.\nDepricated\n"""\n\n@app.post("/chat-lite", description= "  WARNINING DEPRICATED: This API is used to chat with the master summary. Provides high level summaries only. The Application remembers the last 5 conversations that the user had with the code.")\nasync def chat_lite_version(user_question: str = Form(...), project_id: str = Form(...) ,email: str = Form(...) ):\n    try:\n        # Fetch summary from PostgreSQL\n        summary_content = await get_summary_from_db(email, project_id)\n        if not summary_content:\n            raise HTTPException(status_code=404, detail="Summary not found")\n\n        enc = tiktoken.encoding_for_model("gpt-4o")   #needs to be modified to anthropic\n        tokens = enc.encode(summary_content)\n        token_count = len(tokens)\n        if token_count > token_limit:\n            # Truncate the summary to match the token limit\n            truncated_tokens = tokens[:token_limit]\n            summary_content= enc.decode(truncated_tokens)  # Decode tokens back to string\n\n    except Exception as e:\n        raise HTTPException(status_code=400, detail="Failed to read summary file")\n    \n\n    response = await  chat_lite.codebase_qa_with_anthropic(email, project_id, summary_content, user_question)\n    return {"result": response}\n\n\n\n\n#$~ API 4 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis route fetches all projects associated with a user\n\n"""\n\n#$~ Task List ~$#\n"""\n1) Project Name parameter.\n"""\n\n@app.get("/projects", description="This API is used to retrieve all projects for a given user. Provide the user\'s email to get their project list.")\nasync def get_user_projects(\n    email: str = Query(..., description="The email address of the user")\n):\n    try:\n        # Use the renamed function here\n        projects_json = await fetch_user_projects(email)\n        projects_data = json.loads(projects_json)\n        return ProjectsResponse(**projects_data)\n    except json.JSONDecodeError:\n        raise HTTPException(status_code=500, detail="Invalid JSON data returned from database")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    \n\n\n#$~ API 5 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis API retrieves the conversation history for a specific user and request. \nIt returns the last 5 conversations and indicates if it\'s a new chat.\n\n"""\n\n#$~ Task List ~$#\n\n\n@app.get("/conversation-history", description="This API retrieves the conversation history for a specific user and request. It returns the last 5 conversations and indicates if it\'s a new chat.")\nasync def get_conversation_history(\n    email: str = Query(..., description="The email address of the user"),\n    project_id: str = Query(..., description="The unique identifier for the request")\n):\n    try:\n        history = await get_conversation_history_from_db(email, project_id)\n        \n        is_new_chat = len(history) == 0\n        \n        return ConversationHistoryResponse(\n            history=[Message(**msg) for msg in history],\n            is_new_chat=is_new_chat\n        )\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    \n\n    \n#$~ API 6 ~$############################################################################################################################\n#$~ Description ~$#\n\n"""\nThis route fetches the summary from DB and uses Anthropic Prompt caching to let users chat with the codebase.\nThe api feteches an existing chroma db collection under the project Id / Project Id and uses tool rag for generating answers\nAnthropic Claude is used for chat.\nMessage History - Last 5 turns of the conversation.\n"""\n\n#$~ Task List ~$#\n"""\n1) Model encoding - change it to anthropic tokenizer.\n"""\n\n\n#$~ Task List ~$#\n\n\n@app.post("/chat-pro", description="This API uses Caude and . Use the same email and request id as Stage 2. The Application remembers the last 5 conversations that the user had with the code.")\nasync def chat_pro_version (user_question: str = Form(...), project_id: str = Form(...), email: str = Form(...)):\n    try:\n        # Fetch summary from PostgreSQL\n        summary_content = await get_summary_from_db(email, project_id)\n        if not summary_content:\n            raise HTTPException(status_code=404, detail="Summary not found")\n        \n        enc = tiktoken.encoding_for_model("gpt-4")  # Modify as needed for Anthropic\n        tokens = enc.encode(summary_content)\n        token_count = len(tokens)\n        if token_count > token_limit:\n            truncated_tokens = tokens[:token_limit]\n            summary_content = enc.decode(truncated_tokens)\n\n\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=f"Failed to read summary: {str(e)}")\n\n    try:\n        response = await chat_pro.chat(email, project_id, summary_content, user_question)\n        return {"result": response}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f"Error in chat pro: {str(e)}")\n\n#$~ API 7 ~$############################################################################################################################\n#$~ Description ~$#\n\n"""\nDepricated\nThis route fetches generates the mermaid diagram - takes up to 1 minute to return a response.\n"""\n\n#$~ Task List ~$#\n#1 Currently place holder\n\n\n@app.post("/generate-mermaid", description=" WARNING: Depricated. This API uses Caude and. Use the same email and request id as Stage 2. T")\nasync def generate_mermaid_diagrams (user_question: str = Form(...), project_id: str = Form(...), email: str = Form(...)):\n    try:\n        # Fetch summary from PostgreSQL\n        summary_content = await get_summary_from_db(email, project_id)\n        if not summary_content:\n            raise HTTPException(status_code=404, detail="Summary not found")\n\n        # generate summary\n        result = await  mermaid.generate_diagrams(user_question = user_question,  project_id = project_id, email_id = email, summary = summary_content)\n        \n        return {"result": result}\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f"Error in mermaid diagram generation: {str(e)}")\n        \n        \n\n\n#$~ API 8 ~$############################################################################################################################\n#$~ Description ~$#\n\n"""\nThis route deletes a project.\n"""\n\n#$~ Task List ~$#\n#1 Currently place holder\n\n\n@app.post("/delete-project", description="This API will delete the Project summary, associated converstations and the vector collection")\nasync def delete_project (project_id: str = Form(...), email: str = Form(...)):\n    try:\n        result = await delete(  project_id = project_id, email = email)\n        return {"result": result}\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f"Error in deletion: {str(e)}")\n        \n        \n#$~ API 9 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis API retrieves Executive Summary of the project, this replaces the previous get summary api - API 2 \n\n"""\n\n#$~ Task List ~$#\n\n\n@app.get("/executive-summary", description="This API retrieves the Executive Summary of the project and user.")\nasync def get_executive_summary(\n    email: str = Query(..., description="The email address of the user"),\n    project_id: str = Query(..., description="The unique identifier for the project")\n):\n    try:\n        executive_summary = await get_executive_summary_from_db(email, project_id)\n        \n        \n        \n        return  executive_summary\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    \n\n#$~ API 10 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis API retrieves project diagrams this replaces the previous generate mermaid api - API 7 \n\n"""\n\n#$~ Task List ~$#\n\n\n@app.get("/project_diagrams", description="This API retrieves the project\'s mermaid diagrams.")\nasync def get_project_diagram(\n    email: str = Query(..., description="The email address of the user"),\n    project_id: str = Query(..., description="The unique identifier for the project")\n):\n    try:\n        project_diagrams = await get_project_diagrams_from_db(email, project_id)\n        \n        \n        \n        return  project_diagrams\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n\n\n#$~ API 11 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis API creates a pin \n\n"""\n\n#$~ Task List ~$#\n\n\n@app.post("/create_pin", description="This API creates a user pin.")\nasync def create_pin(\n    email: str = Query(..., description="The email address of the user"),\n    project_id: str = Query(..., description="The unique identifier for the project"),\n    topic_name: str = Body(..., description="The topic for the pin"),\n    pin_content: str = Body(..., description="The Pin content")\n):\n    try:\n        await create_pin_in_db(email, project_id, topic_name, pin_content)\n        return {"detail": "Pin Creation successful."}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n#$~ API 12 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis API deletes a pin\n"""\n\n@app.delete("/delete_pin", description="This API deletes a user pin.")\nasync def delete_pin(\n    email: str = Query(..., description="The email address of the user"),\n    pin_id: int = Query(..., description="The ID of the pin to be deleted")\n):\n    try:\n        await delete_pin_from_db(email, pin_id)\n        return {"detail": "Pin deleted successfully."}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n### Fetch Pins by Project API\n\n\n#$~ API 13 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nThis API fetches all pins for a specific project.\n"""\n\n@app.get("/fetch_pins_by_project", description="This API fetches all pins for a specific project.")\nasync def fetch_pins_by_project_route(\n    email: str = Query(..., description="The email address of the user"),\n    project_id: str = Query(..., description="The unique identifier for the project")\n):\n    try:\n        pins = await get_pins_from_db(email, project_id)\n        if pins is None or len(pins) == 0:\n            raise HTTPException(status_code=404, detail="No pins found for this project.")\n        return {"pins": pins}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    \n\n\n#$~ API 14 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nInitiates a blank project with \n\n"""\n\n@app.post("/initialize_project", description="This api takes a project name and associated emails , project name , project description,  ")\nasync def initialize_project(owner_email: str,  project_name: str, project_description: str, emails: Dict[str, str], background_tasks: BackgroundTasks):\n    try:\n    # This will serve as the project id for the call\n        project_id = str(uuid.uuid4())\n\n        \n        await update_project_in_db(project_id, owner_email, project_name, project_description, emails)\n        #formatted_emails = json.dumps(emails)\n        formatted_emails = [{"email": email, "role": role} for email, role in emails.items()]\n        formatted_emails += [{"email": owner_email, "role": "owner"}]\n        await update_status_in_db(emails = json.dumps(formatted_emails), project_id=project_id, project_description = project_description,   project_name = project_name,  status="Awating codebase", summary = None, executive_summary= None, project_diagrams = None)\n\n        return {"detail": "project creation successful.",\n                    "project_id": project_id,\n        }\n    \n                    \n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n\n\n #$~ API 15 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nAdds users to an existing project \n\n"""\n\n@app.post("/add_collabrator", description="This api takes an existing project id and adds a user with a role,  ")\nasync def add_user( project_id: str,  owner_email: str,  emails: Dict[str, str]):\n \n    try:\n\n        formatted_emails = [{"email": email, "role": role} for email, role in emails.items()]\n        await add_user_to_project( project_id= project_id, users = json.dumps(formatted_emails), owner_email= owner_email )\n\n        return {"detail": "user / users added.",\n                    "project_id": project_id,\n        }\n    \n                    \n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail="Internal server error")   \n    \n\n #$~ API 16 ~$############################################################################################################################\n#$~ Description ~$#\n"""\nAdds users to an existing project \n\n"""\n\n@app.post("/delete_user_from_project", description="This api takes the project id and email to be deleted. DO NOT DELETE THE Owner through this route  ")\nasync def  delete_user_from_projects( project_id: str,  email: str, ):\n\n    try:\n    \n        await delete_user_from_project( project_id= project_id, email= email )\n\n        return {"detail": " user deleted.",\n                    "project_id": project_id,\n                    "email" : email\n        }\n    \n                    \n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail="Internal server error")  \n    \n\n #$~ API 17 ~$############################################################################################################################\n#$~ Description ~$#\n"""\ngets users associated with project \n\n"""\n\n@app.post("/get_users_for_project", description="This api takes the project id and returns the users associated with the project ")\nasync def  get_users_for_project( project_id: str):\n\n    try:\n    \n        details = await  get_project_details_by_id( project_id= project_id)\n        emails_list = json.loads(details[\'emails\'])\n        \n\n        return {"users": emails_list}\n    \n                    \n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail="Internal server error")  \n\n############################################################################################################################\n\n\n\nif __name__ == "__main__":\n    import uvicorn\n    uvicorn.run(app, host="0.0.0.0", port=8000)\n\n\n\n\n', 'The file app.py is a primary component of the Harmony Engine application, which serves as the backend API for managing codebase summaries and user projects. It is built using the FastAPI framework and provides a variety of endpoints to handle user requests, process uploaded codebases, generate summaries, and manage projects and user collaborations.\n\nThe file has significant dependencies, including various local database operation functions and chat functionalities which aid in summarizing codebases, managing project data, and facilitating user interactions. It encapsulates several API endpoints, including functionalities for adding codebases, generating summaries, managing projects, and supporting user communication with the system.\n\nKey Features:\n1. Endpoint /addcodebase: Accepts a zip file of codebases for processing and summarizes them using AI, storing results in a database.\n2. Endpoint /generate-summary (deprecated): Was intended to generate a comprehensive report of the codebase but has been marked for deprecation.\n3. Endpoint /projects: Retrieves all projects associated with a user.\n4. Endpoint /conversation-history: Fetches the last 5 conversations for a user.\n5. Endpoint /create_pin and /fetch_pins_by_project: Facilitate the creation and retrieval of pins related to specific projects.\n\nDependencies include numerous database functions for data storage and retrieval, alongside external libraries like FastAPI, Pydantic, and asynchronous file handling. The application architecture is designed to potentially evolve into a microservices structure, emphasizing modularity and minimizing interdependencies.'], ['requirements.txt', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/requirements.txt', 'aiofiles==24.1.0\nannotated-types==0.7.0\nanthropic==0.34.2\nanyio==4.6.0\nasttokens==2.4.1\nasync-timeout==4.0.3\nasyncpg==0.29.0\nattrs==24.2.0\nbackcall==0.2.0\nbeautifulsoup4==4.12.3\nbleach==6.1.0\ncertifi==2024.8.30\nchardet==5.2.0\ncharset-normalizer==3.3.2\nclick==8.1.7\ndecorator==5.1.1\ndefusedxml==0.7.1\nDeprecated==1.2.14\ndistro==1.9.0\ndocopt==0.6.2\nexceptiongroup==1.2.2\nexecuting==2.1.0\nfastapi==0.115.0\nfastjsonschema==2.20.0\nfilelock==3.16.1\nfsspec==2024.9.0\nh11==0.14.0\nhttpcore==1.0.5\nhttpx==0.27.2\nhuggingface-hub==0.25.1\nidna==3.10\nipython==8.12.3\njedi==0.19.1\nJinja2==3.1.4\njiter==0.5.0\njsonschema==4.23.0\njsonschema-specifications==2023.12.1\njupyter_client==8.6.3\njupyter_core==5.7.2\njupyterlab_pygments==0.3.0\nMarkupSafe==2.1.5\nmatplotlib-inline==0.1.7\nmistune==3.0.2\nnbclient==0.10.0\nnbconvert==7.16.4\nnbformat==5.10.4\nopenai==1.49.0\npackaging==24.1\npandocfilters==1.5.1\nparso==0.8.4\npexpect==4.9.0\npickleshare==0.7.5\npillow==10.4.0\npipreqs==0.5.0\nplatformdirs==4.3.6\nprompt_toolkit==3.0.48\nptyprocess==0.7.0\npure_eval==0.2.3\npwinput==1.0.3\npydantic==2.9.2\npydantic_core==2.23.4\nPygments==2.18.0\npython-dateutil==2.9.0.post0\npython-dotenv==1.0.1\npython-multipart==0.0.10\nPyYAML==6.0.2\npyzmq==26.2.0\nreferencing==0.35.1\nregex==2024.9.11\nreportlab==4.2.2\nrequests==2.32.3\nrpds-py==0.20.0\nsix==1.16.0\nsniffio==1.3.1\nsoupsieve==2.6\nstack-data==0.6.3\nstarlette==0.38.6\ntiktoken==0.7.0\ntinycss2==1.3.0\ntokenizers==0.20.0\ntornado==6.4.1\ntqdm==4.66.5\ntraitlets==5.14.3\ntyping_extensions==4.12.2\nurllib3==2.2.3\nuvicorn==0.30.6\nwcwidth==0.2.13\nwebencodings==0.5.1\nwrapt==1.16.0\nyarg==0.1.9\nchromadb==0.5.5\n', 'The file requirements.txt is a configuration file that lists all the dependencies needed for the harmonyengine-core main project. This file ensures that the correct versions of libraries are installed, helping to maintain the environment and functionality of the application. It includes various packages related to web development, data processing, and machine learning, such as FastAPI, OpenAI, and beautifulsoup4, among others.'], ['prompt.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/prompt.py', 'anthropic_prompt = """You are tasked with identifying the high-level user features or business functions in a given code summary. This task is crucial for understanding the main functionalities of a software system from a user or business perspective, Understanding the technical specification is a secondary objective.\n\nHere is the code summary you need to analyze:\n\n<code_summary>\n{{CODE_SUMMARY}}\n</code_summary>\n\nTo complete this task, follow these steps:\n\n1. Carefully read through the entire code summary.\n\n2. As you read, look for descriptions of functionalities that relate to what a user can do with the system or what business processes the system supports.\n\n3. Identify patterns or groupings of related functionalities that could be considered a single high-level feature or business function.\n\n4. Ignore low-level technical details, implementation specifics, or internal system processes that don\'t directly relate to user interactions or business operations.\n\n5. Consider the perspective of an end-user or a business stakeholder when determining what constitutes a high-level feature or function.\n\n6. Create a list of the identified high-level user features or business functions.\n\nWhen you\'ve completed your analysis, provide your output in the following format:\n\n<identified_features>\n1. [First identified feature or function]\n2. [Second identified feature or function]\n3. [Third identified feature or function]\n...\n</identified_features>\n\n<explanation>\nProvide a brief explanation of your reasoning for identifying these features or functions, and mention any challenges you encountered in the process.\n</explanation>\n\nRemember to focus on high-level features that would be meaningful to users or business stakeholders, rather than getting caught up in technical implementation details. Your goal is to provide a clear, concise list of the main functionalities or business processes supported by the system described in the code summary."""', "The file prompt.py appears to contain a prompt template designed for extracting high-level user features or business functions from a software system's code summary. This suggests it is part of a larger AI-driven system aimed at automating the analysis of software features based on user requirements.\n\nThe file serves as a guiding framework to help users understand and identify key functionalities without delving into the technical intricacies, streamlining the process of feature identification.\n\nSummary:\nThis file provides a structured prompt for identifying high-level user features or business functions from code summaries. It's aimed at assisting analytical processes that prioritize user perspectives over technical specifications. The content focuses on extracting meaningful functionalities relevant to users and business stakeholders."], ['railway.json', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/railway.json', '{\n    "$schema": "https://railway.app/railway.schema.json",\n    "build": {\n      "builder": "NIXPACKS"\n    },\n    "deploy": {\n      "startCommand": "uvicorn app:app --host 0.0.0.0 --port 8000 --workers 4 "\n    }\n  }', "This file is a configuration file for the deployment of a web application using Railway, which indicates its role in managing the application's environment rather than containing core business logic. It specifies the build process with NIXPACKS and outlines the deployment command to start a Uvicorn server hosting the app on specified host and port settings. Overall, it supports the infrastructure setup for the application in the larger codebase."], ['delete.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/delete.py', 'from db_operations import delete_project_data\nimport os\nimport chromadb\nimport asyncio\n\n\nasync def delete(project_id: str, email: str):\n    try:\n        await delete_collection(project_id)\n        await delete_project_data(project_id=project_id, email=email)\n        return "Deleted successfully"\n    except Exception as e:\n   \n        # Return an error message\n        return f"An error occurred while deleting project \'{project_id}\' for email \'{email}\': {e}"\n\n\nasync def delete_collection(project_id: str):\n    # Configure ChromaDB\n    absolutepath = os.getenv("ABSOLUTE_PATH")\n    print(absolutepath)\n\n    # Initialize Chroma client\n    client = chromadb.PersistentClient(path=absolutepath)\n\n    try:\n        # Since ChromaDB\'s client methods are synchronous,\n        # we can run them in a thread executor to avoid blocking the event loop\n        loop = asyncio.get_event_loop()\n\n        # Check if the collection exists by running in an executor\n        collections = await loop.run_in_executor(None, client.list_collections)\n        collection_exists = any(\n            collection.name == project_id for collection in collections\n        )\n\n        if collection_exists:\n            # Delete the collection\n            await loop.run_in_executor(None, client.delete_collection, project_id)\n            print(f"Collection \'{project_id}\' deleted successfully.")\n        else:\n            print(f"Collection \'{project_id}\' does not exist.")\n\n    except Exception as e:\n        print(f"An error occurred while deleting the collection: {e}")', 'This file, delete.py, is part of the core functionality of the larger codebase, focusing on deleting project data and associated resources from a database. It defines two main asynchronous functions: one for deleting project data and another for deleting a collection from ChromaDB. Dependencies include the db_operations module for project data deletion and the chromadb library for managing database collections, as well as the environment variable ABSOLUTE_PATH for configuration.'], ['startup.sh', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/startup.sh', '#!/bin/bash\nuvicorn app:app --host 0.0.0.0 --port 8000 --workers 1\n', 'The file startup.sh is a shell script used to launch a web application using the Uvicorn ASGI server. It is a configuration file that helps automate the startup process by specifying the application module, host, port, and the number of worker processes. This file is essential for deploying the application within the larger codebase but does not contain core business logic.'], ['summarizer.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/codebase/summarizer.py', 'from reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.lib.enums import TA_JUSTIFY\nfrom io import BytesIO\nimport re\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.base import MIMEBase\nfrom email.mime.text import MIMEText\nimport smtplib\nfrom email import encoders\nimport os\nimport time\nfrom openai import AsyncOpenAI\nimport asyncio\nimport random\nimport anthropic\nimport json\nfrom typing import Dict, Tuple\nimport tiktoken\nimport chromadb\nfrom chat.mermaid import generate_diagrams\n\n\n\n# Configure API keys\napi_key = os.getenv(\'OPENAI_API_KEY\')\nopen_ai_client = AsyncOpenAI(api_key = api_key)\n\nclient = anthropic.Anthropic()\nclient.api_key = os.getenv(\'ANTHROPIC_API_KEY\')\nanthropic_api_key = os.getenv("ANTHROPIC_API_KEY")\n\n\n# Email configuration for fast mail\nsender_email = "sai_002@harmonyengine.ai"\nsmtp_server = "smtp.fastmail.com"\nsmtp_port = 465  \nsender_password = os.environ.get(\'EMAIL_PASSWORD\')\n\n\nMAX_CHAR_LIMIT = 300000  # Need to figure out a better way to do long context files\n\nclass AsyncRateLimiter:\n    def __init__(self, rate_limit):\n        self.rate_limit = rate_limit\n        self.tokens = rate_limit\n        self.updated_at = time.monotonic()\n        self.lock = asyncio.Lock()\n\n    async def acquire(self):\n        async with self.lock:\n            while self.tokens < 1:\n                self.add_new_tokens()\n                await asyncio.sleep(0.1)\n            self.tokens -= 1\n\n    def add_new_tokens(self):\n        now = time.monotonic()\n        time_since_update = now - self.updated_at\n        new_tokens = time_since_update * self.rate_limit\n        if new_tokens > 1:\n            self.tokens = min(self.tokens + new_tokens, self.rate_limit)\n            self.updated_at = now\n \n \n \nrate_limiter = AsyncRateLimiter(30)\n\n\ndef truncate_text(text, max_tokens=7100):\n    enc = tiktoken.encoding_for_model("text-embedding-3-small")\n    tokens = enc.encode(text)\n    if len(tokens) <= max_tokens:\n        return text\n    return enc.decode(tokens[:max_tokens])\n\nasync def update_vectors (project_id: str, full_summaries: list):\n     # configure chroma db \n    absolutepath = os.getenv("ABSOLUTE_PATH")\n\n    # Initialize Chroma client\n    client = chromadb.PersistentClient(path= absolutepath)\n\n    # Initialize Anthropic embedding function \n    import chromadb.utils.embedding_functions as embedding_functions\n\n    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n                api_key= api_key,\n                model_name="text-embedding-3-large"\n            )\n    # Create a new collection\n    \n    collection = client.create_collection(\n        name =  project_id,\n        embedding_function = openai_ef\n    )\n\n    for full_summary in full_summaries:\n        file_name, file_path, content, summary = full_summary\n        \n        # Create the document with the required sections\n        document = f"File Path: {file_path}\\n\\nSummary:\\n{summary}\\nContent:\\n{content}"\n        truncated_document = truncate_text(document)\n        # Add the document to the collection\n        collection.add(\n            documents = truncated_document,\n            ids= file_path.split(\'extracted_files/\')[-1] if \'extracted_files/\' in file_path else file_path,\n            metadatas=[{"file_name": file_name}]\n        )\n\n    return None\n\n\nasync def summarize_with_openai(file_content: str, path: str) -> str:\n\n   \n    retry_attempts = 10\n    initial_delay = 5  # Initial delay in seconds\n    wait_times = [10, 60, 300, 360, 420, 480, 540, 600, 660, 720] \n    for attempt in range(retry_attempts):\n        try:\n            await rate_limiter.acquire()  \n            response = await open_ai_client.chat.completions.create(\n                model="gpt-4o-mini",\n                messages=[\n                    {"role": "system", "content": "You are an expert software Developer who will generate summaries of code files from a larger codebase. Given a File, 1) Identify the nature of file and how it could relate to a larger codebase 2) If the file is a configuration or boilerplate code file that doesnot contain core business logic or code logic, generate a extreamly short and succint summary of 3 lines. 3) If the file contains code or documentation related to the core features of the codebase, Summarize the identified Features and Business context. Include any dependencies that may depend on other files databases, tables etc. 4) Avoid being too technical. "},\n                    {"role": "user", "content": f"Analyze the following file. Do not include triple quotes or any escape sequences in the result.\\n\\n{path}.  \\n\\n{file_content} "}\n                ],\n                max_tokens=1000\n            )\n            return response.choices[0].message.content\n        \n        except Exception as e:\n            if attempt < retry_attempts - 1:\n                wait_time = wait_times[attempt]\n                print(f"OpenAI API error, retrying (attempt {attempt + 1}) after {wait_time} seconds: {str(e)}")\n                await asyncio.sleep(wait_time)\n            else:\n                return f"Error in OpenAI API: {str(e)}"\n\ndef read_file(file_path):\n    try:\n        with open(file_path, \'r\', encoding=\'utf-8\') as file:\n            return file.read(MAX_CHAR_LIMIT)\n    except Exception as e:\n        return ""           \n\nasync def summarize_file(file_path):\n\n    content = read_file(file_path)\n    if content:\n        print(f"Summarizingfile:  {file_path}")\n        file_path = re.sub(r"/.*/extracted_files/", "", file_path)\n                \n    return file_path, content,  await summarize_with_openai(content, path= file_path)\n    \n\n\n\n\n\n#email used in api 1 \ndef email_summary(summary: str, recipient_emails: str, project_id: str,  project_name: str ):\n    try:\n         \n        email_list = json.loads(recipient_emails)\n\n        for email_info in email_list:\n                email = email_info[\'email\']  \n                print(email)   \n                # Create the email message\n                message = MIMEMultipart()\n                message["From"] = sender_email\n                message["To"] = email\n                message["Subject"] = f"Codebase Analysis Complete: {project_name}"\n\n                # Add a brief message to the email body\n                body =  f"""\n                Dear User,\n\n                Your codebase analysis for project "{project_name}" (ID: {project_id}) is now complete.\n\n                You can now:\n                    1. View the full analysis by logging into your account at \n                        https://app.harmonyengine.ai/\n                    2. Use the chat feature to ask questions about your code\n                    3. Generate Mermaid diagrams to visualize your project structure\n\n                If you have any questions, please don\'t hesitate to contact our \n                support team at sai_002@harmonyengine.ai in the same thread.\n\n                Cheers!\n                The Harmony Engine Team\n                """ \n                message.attach(MIMEText(body, "plain"))\n                # Connect to the SMTP server and send the email\n                with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:\n                    server.login(sender_email, sender_password)\n                    server.send_message(message)\n        return "emails sent "\n                \n\n    except Exception as e:\n        print(f"Failed to send email: {str(e)}")\n\n\n#Generating the executive summary\nasync def generate_executive_summary(summary: str) -> Dict[str, str]:\n    questions_dict = {\n        "Executive Summary": "Based on the provided summary, generate an summary that  captures the key business features of the code aimed at executives.",\n        "Requirements and Setup Details": "Based on the provided summary, identify the requirements, code language, and any other setup details.",\n        "User Personas": "Based on the provided summary, identify potential User Personas of the application.",\n        "User Stories": "Based on the provided summary, identify the User Stories of this application.",\n        "Key Business Modules": "Based on the provided summary, identify the Key Business Modules."\n    }\n    \n    retry_attempts = 5\n    initial_delay = 10  # Initial delay in seconds\n\n    # Initialize a dictionary to store responses\n    responses = {}\n\n    try:\n        # Loop through each question in the dictionary and make API call\n        for title, question in questions_dict.items():\n            for attempt in range(retry_attempts):\n                try:\n                    response = client.beta.prompt_caching.messages.create(\n                        model="claude-3-5-sonnet-20240620",\n                        max_tokens=2000,\n                        system=[\n                            {"type": "text", "text": "You are an AI assistant tasked with analyzing codebases. Format your responses in markdown"},\n                            {"type": "text", "text": f"Here is the summary of a complex codebase: {summary}", "cache_control": {"type": "ephemeral"}}\n                        ],\n                        messages=[{"role": "user", "content": question}]\n                    )\n\n                    # Store the response content in the responses dictionary with the corresponding title\n                    responses[title] = response.content[0].text\n                    break  # Exit the retry loop if the request is successful\n                \n                except Exception as e:\n                    if attempt < retry_attempts - 1:  # If it\'s not the last attempt\n                        sleep_time = initial_delay * (3 ** attempt)  # Exponential backoff\n                        print(f"API Anthropic sleeping for {sleep_time} seconds on attempt {attempt + 1}. Error: {str(e)}")\n                        time.sleep(sleep_time)\n                    else:\n                        responses[title] = f"Error in Anthropic API for question \'{question}\': {str(e)}"\n\n    except Exception as e:\n        print(f"Failed to process requests through Anthropic: {e}")\n\n    return json.dumps(responses, indent=4)\n    \nasync def generate_project_diagrams( project_id, summary):\n\n    questions = {\n            "Program Structure": "Generate a detailed project structure diagram of the codebase it should show the various components of the system",\n            "User Flow": "Generate a detailed user flow diagram for this project",\n            "User Personas": "Generate a detailed  user journey flow for this project"\n        }\n    try: \n    # Initialize a dictionary to store the results\n        diagram_results = {}\n        for key, question in questions.items():\n            # Call the generate_diagrams function for each question\n            diagram_result = await  generate_diagrams( project_id, question, summary)\n            \n            # Append the result to the dictionary with the original key\n            diagram_results[key] = diagram_result\n        return json.dumps(diagram_results, indent=4)     \n    except Exception as e:\n        print(f"Failed to generate mermaid: {str(e)}")\n        \n    \n\n\n\n#############  api 2   ################################  \n#Depricated \n# email used in stage 2 \ndef send_pdf_email(recipient_email, pdf_data):\n    # Create the email object\n\n    msg = MIMEMultipart()\n    msg[\'From\'] = sender_email\n    msg[\'To\'] = recipient_email\n    msg[\'Subject\'] = "Harmony engine - Summary"\n\n    # Email body\n    body = """The Summary of the codebase has been enclosed in this email.\n               \n            Cheers!\n            The Harmony Engine Team\n            """\n    msg.attach(MIMEText(body, \'plain\'))\n\n    # Attach the PDF\n    attachment = MIMEBase(\'application\', \'octet-stream\')\n    attachment.set_payload(pdf_data)\n    encoders.encode_base64(attachment)\n    attachment.add_header(\'Content-Disposition\', \'attachment; filename="summary.pdf"\')\n    msg.attach(attachment)\n\n    # Send the email\n    try:\n        with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:\n            server.login(sender_email, sender_password)\n            server.sendmail(sender_email, recipient_email, msg.as_string())\n            print("Stage 2 - PDF Email sent successfully.")\n    except Exception as e:\n        print(f"Failed to send PDF  email: {e}")  \n\ndef create_pdf(summary, qa_pairs):\n    buffer = BytesIO()\n\n    doc = SimpleDocTemplate(buffer, pagesize=letter, \n                            rightMargin=72, leftMargin=72,\n                            topMargin=72, bottomMargin=18)\n\n    styles = getSampleStyleSheet()\n    styles.add(ParagraphStyle(name=\'Justify\', alignment=TA_JUSTIFY))\n\n    story = []\n\n    # Add summary\n     # Ensure summary is a string\n    if isinstance(summary, list) and summary and hasattr(summary[0], \'text\'):\n        print("Extracting text from the first element in summary list")\n        summary = summary[0].text\n    elif not isinstance(summary, str):\n        raise ValueError("Summary should be a string or a list containing an object with a \'text\' attribute")\n    \n\n    story.append(Paragraph("Summary", styles[\'Heading1\']))\n    story.append(Paragraph(summary, styles[\'Justify\']))\n    story.append(Spacer(1, 12))\n    \n       # Ensure qa_pairs is a string\n    if not isinstance(qa_pairs, str):\n        raise ValueError("qa_pairs should be a string")\n    \n    # Split the qa_pairs string into individual Q&A pairs\n    qa_list = re.split(r\'Q:\', qa_pairs)[1:]  # Skip the first empty element\n\n    # Process each Q&A pair\n    for qa in qa_list:\n        try:\n            # Split each pair into question and answer\n            q, a = qa.split(\'A:\', 1)\n            \n            question = q.strip()\n            answer = a.strip()\n\n            # Extract text from TextBlock if present\n            text_block_match = re.search(r"TextBlock\\(text=[\\"\'](.*?)[\\"\'],", answer, re.DOTALL)\n            if text_block_match:\n                answer = text_block_match.group(1)\n            else:\n                # If no TextBlock, clean up any remaining square brackets\n                answer = re.sub(r\'\\[|\\]\', \'\', answer).strip()\n\n            # Question in bold\n            story.append(Paragraph(f"<b>Q: {question}</b>", styles[\'Normal\']))\n            story.append(Spacer(1, 6))\n            \n            # Answer as regular paragraph\n            story.append(Paragraph(f"A: {answer}", styles[\'Justify\']))\n            story.append(Spacer(1, 12))\n\n        except Exception as e:\n            print(f"Error processing QA pair: {str(e)}")\n            print(f"Problematic QA pair: {qa}")\n\n    # Build the PDF\n    doc.build(story)\n    \n    return buffer.getvalue()\n\n\ndef analyze_summary_with_anthropic(summary: str) -> Tuple[str, str]:\n    questions = [\n        "Based on the provided summary, come up with a list of high-level questions that capture the user stories and business features of the code.",\n        "Based on the code produce an executive summary that captures the key business features of the code."\n    ]\n    \n    retry_attempts = 5\n    initial_delay = 10  # Initial delay in seconds\n\n    try:\n        # Initialize response variables\n        questions_response = None\n        executive_summary_response = None\n\n    \n        # Loop through each question and make API call\n        for idx, user_question in enumerate(questions):\n            for attempt in range(retry_attempts):\n                try:\n                    response = client.beta.prompt_caching.messages.create(\n                        model="claude-3-5-sonnet-20240620",\n                        max_tokens=2000,\n                        system=[\n                            {"type": "text", "text": "You are an AI assistant tasked with analyzing codebases."},\n                            {"type": "text", "text": f"Here is the summary of a complex codebase: {summary}", "cache_control": {"type": "ephemeral"}}\n                        ],\n                        messages=[{"role": "user", "content": user_question}]\n                    )\n                    if idx == 0:\n                        questions_response = response.content\n            \n                    elif idx == 1:\n                        executive_summary_response = response.content\n                    break  # Exit the retry loop if the request is successful\n                except Exception as e:\n                    if attempt < retry_attempts - 1:  # If it\'s not the last attempt\n                        sleep_time = initial_delay * (3 ** attempt)  # Exponential backoff\n                        print(f"API Anthropic sleeping for {sleep_time} seconds on attempt {attempt + 1}. for error {str(e)}")\n                        time.sleep(sleep_time)\n                    else:\n                        error_message = f"Error in Anthropic API for question \'{user_question}\': {str(e)}"\n                        if idx == 0:\n                            questions_response = error_message\n                        elif idx == 1:\n                            executive_summary_response = error_message\n\n    except Exception as e:\n        print(f"Failed to create executive summary or questions, Anthropic: {e}")\n\n    return questions_response, executive_summary_response\n\nasync def exponential_backoff(retries):\n    return min(3 ** retries, 300)  # Cap at 60 seconds\n\nasync def generate_questions_openai(base_questions):\n    retry_count = 0\n    max_retries= 7\n    while retry_count < max_retries:\n        try:\n            # Initialize the OpenAI thread\n            run = await open_ai_client.beta.threads.create_and_run(\n                assistant_id="asst_Xq0G9z95RI3Jl42dWzjloI7O",\n                thread={\n                    "messages": [\n                        {"role": "user", "content": base_questions},\n                    ]\n                }\n            )\n            \n            # Check the status of the thread until it\'s completed\n            status = run.status\n            while status != \'completed\':\n                await asyncio.sleep(5)\n                run = await open_ai_client.beta.threads.runs.retrieve(\n                    thread_id=run.thread_id,\n                    run_id=run.id\n                )\n                status =  run.status\n\n            if status == \'completed\':\n                thread = await open_ai_client.beta.threads.messages.list(run.thread_id)\n                last_message = thread.data[0]\n                data = json.loads(last_message.content[0].text.value)\n                print("Last message content:", data)\n                return data  # successfully completed\n\n            else:\n                print("Thread did not complete successfully.")\n                return None\n\n        except Exception as e:\n            retry_count += 1\n            if retry_count >= max_retries:\n                print(f"Error: OpenAI thread failed after {max_retries} attempts. Last error: {str(e)}")\n                return None  # or raise an exception if preferred\n\n            await exponential_backoff(retry_count)\n            print(f"Retrying... Attempt {retry_count + 1} after backoff")\n\nasync def generate_answers_anthropic(summary: str, custom_query: str) -> str:\n    retry_attempts = 5\n    initial_delay = 25  # Initial delay in seconds\n    \n    for attempt in range(retry_attempts):\n        try:\n            \n            \n            print("Analyzing summary with custom query:", custom_query)\n\n            response = client.beta.prompt_caching.messages.create(\n                model="claude-3-haiku-20240307",\n                max_tokens=2000,\n                system=[\n                    {"type": "text", "text": "You are an AI assistant tasked with analyzing codebases."},\n                    {"type": "text", "text": f"Here is the summary of a complex codebase: {summary}", "cache_control": {"type": "ephemeral"}}\n                ],\n                messages=[{"role": "user", "content": custom_query}]\n            )\n            return response.content\n        except anthropic.exceptions.RateLimitError as e:\n            if attempt < retry_attempts - 1:  # If it\'s not the last attempt\n                retry_after = int(e.response.headers.get(\'Retry-After\', initial_delay))\n                sleep_time = retry_after + random.uniform(0, 1)  # Add some jitter\n                print(f"RateLimitError: Sleeping for {sleep_time} seconds")\n                await asyncio.sleep(sleep_time) \n            else:\n                return f"Error in Anthropic API: {str(e)}"\n        except Exception as e:\n            if attempt < retry_attempts - 1:  # If it\'s not the last attempt\n                sleep_time = initial_delay * (2 ** attempt) + random.uniform(0, 1)  # Exponential backoff with jitter\n                print(f"Exception: {str(e)} - API 2 , Anthropic answer, Sleeping for {sleep_time} seconds")\n                time.sleep(sleep_time)\n            else:\n                return f"Error in Anthropic API: {str(e)}"\n    \n\nasync def generate_responses(final_question, email, summary_content, project_id, executive_summary):\n    responses = []\n    response_text = ""\n\n    # update_status_in_db(email, project_id, "STAGE 2 Generating detailed responses")\n\n    for category in final_question["questions"]:\n        print(f"Processing Heading: {category[\'heading\']}")\n\n        for question in category["questions"]:\n            print(f"Processing question: {question}")\n            retries = 0\n            while True:\n                try:\n                    await asyncio.sleep(5)\n                    answer = await generate_answers_anthropic(summary_content, custom_query=question)\n                    responses.append({"question": question, "answer": answer})\n                    response_text += f"Q: {question}\\nA: {answer}\\n\\n"\n                    break  # Success, exit the retry loop\n                except Exception as e:\n                    retries += 1\n                    if retries > 5:\n                        # update_status_in_db(email, project_id, f"Error: STAGE 2 Failed to process question after {retries} attempts")\n                        print(f"Failed after {retries} attempts: {str(e)}")\n                        break\n                    await exponential_backoff(retries)\n\n    with open(\'responses.txt\', \'w\') as file:\n        file.write(response_text)\n\n    try:\n        # update_status_in_db(email, project_id, "STAGE 2 Creating PDF")\n        pdf_data = create_pdf(executive_summary, response_text )\n        \n        # update_status_in_db(email, project_id, "STAGE 2 Sending email")\n        send_pdf_email(email, pdf_data)\n        # update_status_in_db(email, project_id, "Ready")\n        print("Email sent successfully")\n    except Exception as e:\n        # update_status_in_db(email, project_id, f"STAGE 2 Error: Failed to create PDF or send email - {str(e)}")\n        print(f"Failed to create PDF or send email: {e}")\n\n\n\n#API 3 \n#Used to fetch the result of the computed summary ', 'The file `summarizer.py` is a core component of the Harmony Engine codebase, designed to facilitate the summarization of code files through the integration of AI-powered services. It leverages various libraries and APIs to analyze source code, generate summaries, and send notification emails to users regarding the analysis results.\n\nKey Features and Business Context:\n- **Summarization Process**: Asynchronously summarizes codebase files using AI tools (OpenAI and Anthropic) by reading file content, truncating text, and generating concise summaries based on provided complex code.\n- **Email Notifications**: Automates sending email notifications upon completion of summary analysis to users with details about the project and how to access the analysis.\n- **Dependency Management**: Interacts with ChromaDB for managing summaries and utilizes several environmental variables for configuration, indicating a reliance on external services and secure credential management.\n\nDependencies include:\n- External AI services (OpenAI, Anthropic) for natural language processing.\n- ChromaDB for persistent storage of summaries.\n- Email capabilities through SMTP configurations.'], ['edit columns migrations.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/migration scripts/edit columns migrations.py', 'import asyncio\nimport asyncpg\nfrom typing import List\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Database connection parameters\nDB_PARAMS = {\n    \'database\': os.environ.get(\'DB_NAME\'),\n    \'user\': os.environ.get(\'DB_USER\'),\n    \'password\': os.environ.get(\'DB_PASSWORD\'),\n    \'host\': os.environ.get(\'DB_HOST\'),\n    \'port\': os.environ.get(\'DB_PORT\')\n}\n\nasync def get_db_connection() -> asyncpg.Connection:\n    return await asyncpg.connect(**DB_PARAMS)\n\nasync def get_summary_tables(conn: asyncpg.Connection) -> List[str]:\n    query = """\n        SELECT table_name \n        FROM information_schema.tables \n        WHERE table_schema = \'public\' AND table_name LIKE \'summaries_%\'\n    """\n    rows = await conn.fetch(query)\n    return [row[\'table_name\'] for row in rows]\n\nasync def column_exists(conn: asyncpg.Connection, table_name: str, column_name: str) -> bool:\n    query = f"""\n        SELECT EXISTS (\n            SELECT 1 \n            FROM information_schema.columns \n            WHERE table_name=\'{table_name}\' AND column_name=\'{column_name}\'\n        )\n    """\n    return await conn.fetchval(query)\n\nasync def update_null_roles():\n    conn = None\n    try:\n        conn = await get_db_connection()\n        tables = await get_summary_tables(conn)\n\n        for table_name in tables:\n            # Check if \'role\' column exists\n            if await column_exists(conn, table_name, \'role\'):\n                # Update null or empty roles to \'owner\'\n                update_query = f"""\n                    UPDATE {table_name}\n                    SET role = \'owner\'\n                    WHERE role IS NULL OR role = \'\'\n                """\n                result = await conn.execute(update_query)\n                print(f"Updated null/empty roles in table {table_name}: {result}")\n            else:\n                print(f"Column \'role\' does not exist in table: {table_name}")\n\n    except Exception as e:\n        print(f"An error occurred: {e}")\n\n    finally:\n        if conn:\n            await conn.close()\n\n# Run the script\nasyncio.run(update_null_roles())', "The file is a migration script designed to update specific columns in a PostgreSQL database. It focuses on checking summary tables for the existence of a 'role' column and updating any null or empty values to 'owner'. This script is crucial for maintaining data integrity and ensures that roles are properly assigned, potentially affecting user permissions in the larger application."], ['projects_table_migrations.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/migration scripts/projects_table_migrations.py', 'import asyncio\nimport asyncpg\nfrom typing import List\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Database connection parameters\nDB_PARAMS = {\n    \'database\': os.environ.get(\'DB_NAME\'),\n    \'user\': os.environ.get(\'DB_USER\'),\n    \'password\': os.environ.get(\'DB_PASSWORD\'),\n    \'host\': os.environ.get(\'DB_HOST\'),\n    \'port\': os.environ.get(\'DB_PORT\')\n}\n\nasync def get_db_connection() -> asyncpg.Connection:\n    return await asyncpg.connect(**DB_PARAMS)\n\nasync def get_summary_tables(conn: asyncpg.Connection) -> List[str]:\n    query = """\n        SELECT table_name \n        FROM information_schema.tables \n        WHERE table_schema = \'public\' AND table_name LIKE \'summaries_%\'\n    """\n    rows = await conn.fetch(query)\n    return [row[\'table_name\'] for row in rows]\n\nasync def extract_email_from_table_name(table_name: str) -> str:\n    # Remove \'summaries_\' prefix\n    email_part = table_name[10:]\n    # Reconstruct email\n    return email_part\n\nasync def process_tables():\n    conn = None\n    try:\n        conn = await get_db_connection()\n        tables = await get_summary_tables(conn)\n\n        for table_name in tables:\n            email = await extract_email_from_table_name(table_name)\n            \n            # Get owner records from summary table\n            query = f"""\n                SELECT \n                    project_id,\n                    project_name,\n                    COALESCE(NULLIF(project_description, \'\'), \' \') as project_description,\n                    created_at,\n                    role\n                FROM {table_name}\n                WHERE role = \'owner\'\n            """\n            owner_records = await conn.fetch(query)\n\n            for record in owner_records:\n                # Check if project exists in projects table\n                exists_query = """\n                    SELECT EXISTS(\n                        SELECT 1 \n                        FROM projects_table \n                        WHERE project_id = $1\n                    )\n                """\n                project_exists = await conn.fetchval(exists_query, record[\'project_id\'])\n\n                if not project_exists:\n                    # Insert new project\n                    insert_query = """\n                        INSERT INTO projects_table (\n                            project_id,\n                            owner_email,\n                            email,\n                            project_name,\n                            project_description,\n                            user_role,\n                            created_at\n                        ) VALUES ($1, $2, $3, $4, $5, $6, $7)\n                    """\n                    await conn.execute(\n                        insert_query,\n                        record[\'project_id\'],\n                        email,\n                        email,\n                        record[\'project_name\'],\n                        record[\'project_description\'],\n                        record[\'role\'],\n                        record[\'created_at\']\n                    )\n                    print(f"Inserted project {record[\'project_id\']} from {email}")\n                else:\n                    print(f"Skipped project {record[\'project_id\']} - already exists")\n\n    except Exception as e:\n        print(f"An error occurred: {e}")\n        raise e\n\n    finally:\n        if conn:\n            await conn.close()\n\n# Run the script\nasyncio.run(process_tables())', 'The file projects_table_migrations.py is a migration script designed for managing and inserting project-related data into a database. It establishes a connection to the database, retrieves summary tables related to projects, and processes owner records to either insert new project entries into the projects_table or skip existing ones. It directly interacts with the database schema, specifically targeting the public tables and requiring configuration settings like database name, user, password, host, and port from environment variables.'], ['add column migration script.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/migration scripts/add column migration script.py', 'import asyncio\nimport asyncpg\nfrom typing import List\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Database connection parameters\nDB_PARAMS = {\n    \'database\': os.environ.get(\'DB_NAME\'),\n    \'user\': os.environ.get(\'DB_USER\'),\n    \'password\': os.environ.get(\'DB_PASSWORD\'),\n    \'host\': os.environ.get(\'DB_HOST\'),\n    \'port\': os.environ.get(\'DB_PORT\')\n}\n\nasync def get_db_connection() -> asyncpg.Connection:\n    return await asyncpg.connect(**DB_PARAMS)\n\nasync def get_summary_tables(conn: asyncpg.Connection) -> List[str]:\n    query = """\n        SELECT table_name \n        FROM information_schema.tables \n        WHERE table_schema = \'public\' AND table_name LIKE \'summaries_%\'\n    """\n    rows = await conn.fetch(query)\n    return [row[\'table_name\'] for row in rows]\n\nasync def column_exists(conn: asyncpg.Connection, table_name: str, column_name: str) -> bool:\n    query = f"""\n        SELECT EXISTS (\n            SELECT 1 \n            FROM information_schema.columns \n            WHERE table_name=\'{table_name}\' AND column_name=\'{column_name}\'\n        )\n    """\n    return await conn.fetchval(query)\n\nasync def add_column_if_not_exists():\n    conn = None\n    try:\n        conn = await get_db_connection()\n        tables = await get_summary_tables(conn)\n\n        for table_name in tables:\n            if not await column_exists(conn, table_name, \'role\'):\n                alter_table_query = f"ALTER TABLE {table_name} ADD COLUMN role TEXT"\n                await conn.execute(alter_table_query)\n                print(f"Column \'role\' added to table: {table_name}")\n            else:\n                print(f"Column \'role\' already exists in table: {table_name}")\n\n    except Exception as e:\n        print(f"An error occurred: {e}")\n\n    finally:\n        if conn:\n            await conn.close()\n\n# Run the script\nasyncio.run(add_column_if_not_exists())\n', 'This file is a migration script designed for database schema management. It connects to a PostgreSQL database and adds a new column named "role" to existing summary tables, if it does not already exist. The script relies on environment variables for database connection parameters and utilizes asynchronous programming for efficient execution.'], ['chat_pro.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/chat/chat_pro.py', 'import os\nimport chromadb\nfrom chromadb.config import Settings\nfrom chromadb.utils import embedding_functions\nimport json\nfrom anthropic import Anthropic\nfrom db_operations import  store_conversation_in_db, get_conversation_history_from_db \nimport chromadb.utils.embedding_functions as embedding_functions\nanthropic_api_key = os.getenv("ANTHROPIC_API_KEY")\nabsolutepath = os.getenv("ABSOLUTE_PATH")\n\n\n\n# Initialize Anthropic client\nanthropic = Anthropic(api_key=anthropic_api_key)\n\nasync def summarize_early_exchanges(messages: list[dict], num_exchanges: int = 4) -> str:\n    if len(messages) <= num_exchanges :  # If we don\'t have enough messages to summarize\n        return ""\n    \n    early_messages = messages[:num_exchanges * 2]  # Get the first 4 exchanges (8 messages)\n    summary_prompt = "Summarize the following conversation concisely:\\n\\n"\n    for msg in early_messages:\n        summary_prompt += f"{msg[\'role\'].capitalize()}: {msg[\'content\']}\\n\\n"\n    \n    summary_response = anthropic.beta.prompt_caching.messages.create(\n        model="claude-3-5-sonnet-20240620",\n        max_tokens=2000,\n        system=[{"type": "text", "text": "You are an AI assistant tasked with summarizing conversations. Provide a brief summary."}],\n        messages=[{"role": "user", "content": summary_prompt}]\n    )\n    \n    return summary_response.content[0].text\n\ndef synthesize_information(retrieved_info):\n    synthesis_response = anthropic.beta.prompt_caching.messages.create(\n        model="claude-3-5-sonnet-20240620",\n        max_tokens=1000,\n        system=[{"type": "text", "text": "Analyze the following information retrieved from multiple files. Synthesize key points and relationships between different parts of the codebase."}],\n        messages=[{"role": "user", "content": retrieved_info}]\n    )\n    return synthesis_response.content[0].text\n\nasync def chat(email_id: str, project_id: str, summary: str, user_question: str) -> str:\n    try:\n        \n        client = chromadb.PersistentClient(path= absolutepath)\n\n        \n\n        # Get the collection for the project\n        collection_name = project_id\n        \n\n        openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n                    api_key = os.getenv(\'OPENAI_API_KEY\'),\n                    model_name="text-embedding-3-large")\n        collection = client.get_collection(name=collection_name, embedding_function=openai_ef)\n\n        \n\n        def query_chroma_db(query):\n            results = collection.query(\n                query_texts=query,\n                n_results=4\n            )\n            \n            context = ""\n            for result in results[\'documents\'][0]:\n                context += f"results: {result}\\n"\n              \n              \n            \n            return context  \n\n        # Get the relevant conversation history from the database\n        conversation_messages = await get_conversation_history_from_db(email_id, project_id)\n        \n        \n\n        # Prepare the messages for the API call\n        api_messages = []\n\n        # Prepare the system message\n        system_message = [\n            {"type": "text", "text": f""" You are an AI assistant tasked with analyzing codebases.\n                                        1) Go through the provided summary\n                                        2) Then Study the User question and come-up with a list of files that may have details that can address the user question\n                                        3) Based on your list of files, formulate a query that will return the relevant context from a vector database. This query should be designed to retrieve code snippets that are most likely to answer the user\'s question.\n                                  4) Call the query chroma Tool with the list of files """},\n            {"type": "text", "text": f"Here is the summary of a complex codebase: {summary}", "cache_control": {"type": "ephemeral"}}\n            \n        ]\n        \n        # Add initial message with summary if conversation history is empty\n        if not conversation_messages:\n            api_messages.append({"role": "user", "content": user_question})\n            # await store_conversation_in_db(email_id, project_id, "user", user_question)\n        else:\n            # Summarize the early part of the conversation\n            early_summary = await summarize_early_exchanges(conversation_messages[:-2])  # Summarize all but last exchange\n            \n            if early_summary:\n                system_message.append({"type": "text", "text": f"Earlier conversation summary: {early_summary}"})\n            \n            # Ensure the conversation history alternates correctly\n            for i, msg in enumerate(conversation_messages[-2:]):  # Add only the last exchange\n                if i % 2 == 0:\n                    api_messages.append({"role": "user", "content": msg["content"]})\n                else:\n                    api_messages.append({"role": "assistant", "content": msg["content"]})\n            \n            # Add the new user question\n            api_messages.append({"role": "user", "content": user_question})\n            #await store_conversation_in_db(email_id, project_id, "user", user_question)\n\n        # Print api_messages for debugging\n        print("API Messages:", api_messages)\n\n        \n        \n        # Define the Chroma DB tool\n        chroma_tool = [\n                         {\n                             "name" : "Querycodebase",\n                             "description"  : "Query a vector database to retrieve specific information at a code level. This returns the actual code in the project. It takes the Query and does a Vector Search",\n                             "input_schema"  : {\n                                                  "type" : "object", \n                                                   "properties": { \n                                                    "Query" : {\n                                                                        "type" : "string",\n                                                                        "description" : "The query to search for in the database, the Query must be specific in nature with references to the  specific files to search for , DOT NOT GIVE IT A VAGUE QUERY"\n                                                                      }\n                                                                 },\n\n                                 "required" : ["Query"]\n                                     \n                                 }\n                            }\n                        \n                         ] \n\n        # Generate a response using Anthropic with tools\n\n        response = anthropic.beta.prompt_caching.messages.create(\n            model="claude-3-5-sonnet-20240620",  # Update to the latest available model\n            max_tokens=2000,\n            system=system_message,\n            messages=api_messages,\n            tool_choice = {"type": "tool", "name": "Querycodebase"},\n            tools=chroma_tool\n        )\n\n        print(response)\n        ai_response =[]\n          \n        try:\n            if response.stop_reason == \'tool_use\':\n               rag_query = response.content[0].input\n               response_type = "tool_call"\n            else:\n             ai_response = response.content[0].text \n             response_type = "ai_response"\n\n        except Exception as e:\n            return str(e)\n\n        if response_type == "tool_call"  :\n            query = rag_query["Query"]\n            db_result = query_chroma_db(query)\n          \n            full_response = f"\\n\\nRetrieved information:\\n```\\n{db_result}\\n```\\n\\n"\n\n            # Feed the retrieved information back into the model for a final response\n            final_system_message = [\n                {"type": "text", "text": "You are an AI assistant tasked with analyzing codebases. Use the retrieved information to provide a comprehensive response.  you should not make any more tool calls, if you cant answer the question in high confidence ask the user to provide more details on where the code could be located. IMPORTANT: Your Response should be a neatly formated Markdown."},\n                {"type": "text", "text": f"Here is the summary of a complex codebase: {summary}", "cache_control": {"type": "ephemeral"}},\n                {"type": "text", "text": f"Retrieved information:\\n{full_response}", "cache_control": {"type": "ephemeral"}}\n            ]\n\n            final_response = anthropic.beta.prompt_caching.messages.create(\n                model="claude-3-5-sonnet-20240620",  # Update to the latest available model\n                max_tokens=3000,\n                system=final_system_message,\n                messages=api_messages\n            )\n\n            ai_response = final_response.content[0].text \n\n        else:\n            pass \n\n        # Print the final response\n        print(ai_response)\n        last_response = ai_response\n\n        # Add the AI\'s response to the conversation history\n        await store_conversation_in_db(email_id, project_id, "user", user_question)\n        await store_conversation_in_db(email_id, project_id, "assistant", last_response)\n        \n        return last_response\n    except Exception as e:\n        return str(e)\n\n', 'The file chat_pro.py is a core component of a conversational AI system designed to interact with users, analyze codebases, and summarize conversations. It relies on the Anthropic AI model for generating responses and integrates with a Chroma database to manage and query conversation history.\n\nFeatures included in this file:\n1. **Conversation Summarization**: It summarizes early messages in a conversation to provide context when users ask questions.\n2. **Information Synthesis**: It retrieves key points from previously stored messages to create a cohesive response based on user queries.\n3. **Database Integration**: Functions to store and retrieve conversation histories from a database, ensuring context is maintained throughout interactions.\n4. **Chroma DB Queries**: Integrates with a vector database to extract relevant code snippets from the codebase based on user queries.\n\nDependencies:\n- External services including Anthropic for AI responses and ChromaDB for managing conversation contexts.\n- Database operations defined in `db_operations` for storing and retrieving conversations.'], ['mermaid.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/chat/mermaid.py', 'import os\nimport anthropic\nimport json\nfrom typing import Dict, Any\nclient = anthropic.Anthropic()\nclient.api_key = os.getenv(\'ANTHROPIC_API_KEY\')\n\n\nasync def generate_diagrams( project_id: str,  user_question: str, summary: str) -> str:\n\n    try:\n\n        api_messages = []\n        api_messages.append({"role": "user", "content": user_question})\n    \n        mermaid_tool = [\n                         {\n                             "name" : "mermaid_diagram_generator",\n                             "description"  : "generates a mermaid diagram based on the mermaid code provided",\n                             "input_schema"  : {\n                                                  "type" : "object", \n                                                   "properties": { \n                                                    "mermaid_code" : {\n                                                                        "type" : "string",\n                                                                        "description" : "The code will be run in a mermaid renderer"\n                                                                      }\n                                                                 },\n\n                                 "required" : ["ticker"]\n                                     \n                                 }\n                            }\n                        \n                         ] \n        # Print api_messages for debugging\n        print("API Messages:", api_messages)\n\n        response = client.beta.prompt_caching.messages.create(\n            model="claude-3-5-sonnet-20240620",\n            max_tokens=2000,\n            temperature = 0.0,\n            tool_choice = {"type": "tool", "name": "mermaid_diagram_generator"},\n            tools = mermaid_tool,\n            system=[\n                    {"type": "text", "text": "You are an AI Production owner  tasked with analyzing codebases for Technicsl, User Journerys, Features or over all flow. Based on the users request you must provide a Mermid diagram only."},\n                    {"type": "text", "text": f"Here is the summary of a complex codebase: {summary}", "cache_control": {"type": "ephemeral"}}\n                ],\n            messages=api_messages\n        )\n\n        # Add the AI\'s response to the conversation history\n        try:\n           if response.stop_reason == \'tool_use\':\n               mermaid_code = response.content[0].input\n           else:\n               raise Exception(" Error calling the mermaid generation core api")\n               \n        except Exception as e:\n            return str(e) \n        \n        return mermaid_code\n    except Exception as e:\n        return str(e)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n', "The file mermaid.py is part of a chat-based application that utilizes an AI model to generate diagrams based on user queries. It integrates with the Anthropics API for prompt management and processes user input to create a mermaid diagram, likely aiming to visualize complex codebases or technical flows. Key dependencies include the Anthropics SDK and an environmental variable for authentication.\n\nThe main feature of this file is the asynchronous function generate_diagrams, which takes a project ID, user question, and summary to generate a mermaid code snippet. It requires structured input for the diagram and manages responses from the AI, ensuring it responds appropriately based on the tool's output."], ['chat_lite.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/chat/chat_lite.py', 'import os\nfrom db_operations import  store_conversation_in_db, get_conversation_history_from_db \nimport anthropic\n\nclient = anthropic.Anthropic()\nclient.api_key = os.getenv(\'ANTHROPIC_API_KEY\')\n\n\nasync def codebase_qa_with_anthropic(email_id: str, project_id: str, summary: str, user_question: str) -> str:\n\n    try:\n          # Get the relevant conversation history from the database\n        conversation_messages = await get_conversation_history_from_db(email_id, project_id)\n        \n        # Prepare the messages for the API call\n        api_messages = []\n        \n        # Add initial message with summary if conversation history is empty\n        if not conversation_messages:\n            \n            api_messages.append({"role": "user", "content": user_question})\n            await store_conversation_in_db(email_id, project_id, "user", user_question)\n        else:\n            # Ensure the conversation history alternates correctly\n            for i, msg in enumerate(conversation_messages):\n                if i % 2 == 0:\n                    api_messages.append({"role": "user", "content": msg["content"]})\n                else:\n                    api_messages.append({"role": "assistant", "content": msg["content"]})\n            \n            # Add the new user question\n            api_messages.append({"role": "user", "content": user_question})\n            await store_conversation_in_db(email_id, project_id, "user", user_question)\n\n        # Print api_messages for debugging\n        print("API Messages:", api_messages)\n\n        response = client.beta.prompt_caching.messages.create(\n            model="claude-3-5-sonnet-20240620",\n            max_tokens=2000,\n            system=[\n                    {"type": "text", "text": "You are an AI assistant tasked with analyzing codebases."},\n                    {"type": "text", "text": f"Here is the summary of a complex codebase: {summary}", "cache_control": {"type": "ephemeral"}}\n                ],\n            messages=api_messages\n        )\n\n        # Add the AI\'s response to the conversation history\n        ai_response = response.content[0].text\n        await store_conversation_in_db(email_id, project_id, "assistant", ai_response)\n        \n        return ai_response\n    except Exception as e:\n        return str(e)', 'The file chat_lite.py is a key component of the chat functionality in the harmonyengine codebase, facilitating interactions with the Anthropics API for natural language processing. It handles user queries in relation to a codebase, retrieving and storing conversation histories in a database.\n\nKey features include:\n- Integration with the Anthropics API for generating responses based on user questions about a codebase.\n- Asynchronous handling of database operations to fetch and store conversation messages related to user interactions.\n \nDependencies include the db_operations module for database interactions, specifically the functions store_conversation_in_db and get_conversation_history_from_db, which manage conversation data tied to user email IDs and project IDs.'], ['__init__.py', '/tmp/tmpdfs717jf/extracted_files/harmonyengine-core-main/chat/__init__.py', '#API 3 AND 6', 'The file `harmonyengine-core-main/chat/__init__.py` likely serves as an initializer for the chat module within a larger codebase, which could be part of a messaging or communication system. This module is likely responsible for managing chat-related functionalities.\n\nIt is a boilerplate file that sets up the structure and imports necessary components for the chat module. It does not contain core business logic.']]


import tiktoken

def truncate_text(text, max_tokens=7100):
    enc = tiktoken.encoding_for_model("text-embedding-3-large")
    tokens = enc.encode(text)
    if len(tokens) <= max_tokens:
        print(f"less than 7k tokens: {len(tokens)}")
        return text
    else:
        print(f"more than 7k tokens: {len(tokens)}")    
        return enc.decode(tokens[:max_tokens])


for full_summary in list:
        file_name, file_path, content, summary = full_summary
        print(f"the file name is  {file_name}")
        # Create the document with the required sections
        document = f"File Path: {file_path}\n\nSummary:\n{summary}\nContent:\n{content}"
        truncated_document = truncate_text(document)
        print(truncated_document)
       

       